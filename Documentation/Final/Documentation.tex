\documentclass{article}
\usepackage[T1]{fontenc}
\usepackage[polish]{babel}
\usepackage[utf8]{inputenc}
\usepackage{biblatex}
\usepackage{titling,lipsum}

\addbibresource{bibliography.bib}

\title{Grafy i sieci - wykrywanie społeczności\\dokumentacja końcowa}
\date{\today}
\author{Ireneusz Stanicki, Mateusz Śliwakowski,\\Bartłomiej Truszkowski, Przemysław Woźniakowski}

\begin{document}
	\begin{titlingpage}
		\maketitle
	\end{titlingpage}
	\pagenumbering{arabic}

\tableofcontents
\newpage

%-----------------------------------------------------%
%Wstęp
%-----------------------------------------------------%
\section{Wstęp}

%-----------------------------------------------------%
%Algorytmy
%-----------------------------------------------------%
\section{Algorytmy}

%-----------------------------------------------------%
%Girvan Newman
%-----------------------------------------------------%
\subsection{Algorytm Girvan-Newmana}
\subsubsection{Implementacja}
\subsubsection{Podjęte decyzje}

%-----------------------------------------------------%
%LPA
%-----------------------------------------------------%
\subsection{Label Propagation Algorithm}
\subsubsection{Implementacja}
\subsubsection{Podjęte decyzje}

%-----------------------------------------------------%
%OCDLCE
%-----------------------------------------------------%
\subsection{Overlapping Community Detection by Local Community Expansion}
\subsubsection{Implementacja}
\subsubsection{Podjęte decyzje}

%-----------------------------------------------------%
%Louvain
%-----------------------------------------------------%
\subsection{Algorytm Louvain}

\subsubsection{Implementacja}
Algorytm Louvain został zaimplementowany od podstaw. Pierwszym krokiem było dodanie wszystkich funkcji pomocniczych, koniecznych do obliczenia wartości takich jak liczba połączeń do społeczności (nie wliczając pętli) czyli $\Sigma_{tot}$, liczba połączeń wewnątrz społeczności czyli $\Sigma_{in}$, czy liczba połączeń do wierzchołka k rozpatrywanej społeczności $k_{in}$. Funkcje te wywoływane są tylko w koniecznych sytuacjach. W miarę możliwości odpowiednie parametry są uaktualniane, zamiast ciągłego ich przeliczania.\\ \\
Podstawą algorytmu jest funkcja $louvain\_ iteration$, która odpowiada pojedynczej iteracji algorytmu. Jej zadaniem jest uaktualnianie tablicy przynależności, która mówi w jakiej społeczności aktualnie znajduje się wierzchołek.\\ Na początku wyznaczana jest w niej suma wag krawędzi w grafie i tworzona jest kopia tablicy przynależności, a następnie za pomocą pętli iterujemy po wszystkich wierzchołkach. Kolejność rozpatrywania wierzchołków zależy od tablicy $permut$, która jest losową permutacją liczb od $1$ do $n$ ($n$-liczba wierzchołków). \\Dla każdego wierzchołka rozpatrywane są społeczności do których należą jego sąsiedzi (każda społeczność jest brana pod uwagę tylko raz). Wierzchołek jest usuwany ze swojej społeczności i umieszczany w społeczności sąsiada, a następnie obliczany jest przyrost modularności. Jeżeli przyrost dla społeczności jest większy od aktualnego maksymalnego przyrostu ($max\_ mod\_ change$) to staje się on nowym maksymalnym przyrostem, a społeczność ta jest zapamiętywana. Następnie wierzchołek wraca do swojej społeczności i proces jest powtarzany dla każdego sąsiada. \\
Warto tu przypomnieć wzór na zmianę modularności: $$\Delta Q = [\frac{\Sigma_{in} +2k_{i,in}}{2m} - (\frac{\Sigma_{tot} + k_i}{2m})^2] - [\frac{\Sigma_{in}}{2m} - (\frac{\Sigma_{tot}}{2m})^2 - (\frac{k_i}{2m})^2]$$ gdzie $k_i$ to stopień wierzchołka $i$, $k_{in}$ to suma wag krawędzi między wierzchołkiem $i$ i wierzchołkami ze społeczności, do której trafia $i$, $\Sigma_{in}$ to suma wag krawędzi wewnątrz tej społeczności, a $\Sigma_{tot}$ to suma wag krawędzi wewnątrz społeczności z której usuwamy wierzchołek $i$.\\Jest to jednak rozpisany wzór i w implementacji wykorzystana jest jego skrócona wersja: $$\Delta Q = [\frac{k_{i,in}}{m} - \frac{\Sigma_{tot}*k_i}{2m^2}]$$ \\
\\
Po przeiterowaniu wszystkich sąsiadów wierzchołka, sprawdzane jest czy znaleziono społeczność zwiększającą modularność, która nie jest oryginalną społecznością wierzchołka. Jeżeli tak jest, to odnotowywana jest zmiana, oraz uaktualniane są odpowiednie wartości i tablica przynależności (zarówno dla danego wierzchołka, jak i dla wszystkich, które zostały z nim scalone).
\\
Po przejściu wszystkich wierzchołków, tablica przynależności jest podmieniana i zwracana jest wartość logiczna, mówiąca czy nastąpiła zmiana.  
\\
Równie ważna funkcją w algorytmie jest funkcja scalająca wierzchołki znajdujące się w jednej społeczności - $merge\_ communities$. Tworzy ona nowy graf, w którym każdej społeczności odpowiada wierzchołek umieszczony w tej społeczności. Suma wag krawędzi między wierzchołkami wewnątrz społeczności staje się pętlą w nowym grafie, a suma krawędzi między społecznościami wagą krawędzi pomiędzy odpowiadającymi im wierzchołkami.
\\ \\
Cały algorytm wykonywany jest w funkcji $louvain\_ algorithm$. Wyznaczana jest w niej wartość $\Sigma_{tot}$ dla każdej społeczności, tworzona jest kopia grafu oraz każdy wierzchołek umieszczany jest w swojej społeczności. Następnie w pętli wykonywana jest funkcja $louvain\_ iteration$, tak długo jak powoduje ona jakieś zmiany społeczności. Po każdej iteracji społeczności są scalane. Wynikiem algorytmu jest tablica przynależności. Algorytm nie modyfikuje oryginalnego grafu.

\subsubsection{Implementacja dla nachodzących społeczności}
Algorytm dla społeczności nachodzących wykorzystuje algorytm dla społeczności rozłącznych. Został przede wszystkim zaimplementowany do współpracy z algorytmem Louvaina, ale może działać też z innym nie deterministycznymi algorytmami. Muszą one jednak zwracać tablicę przynależności. \\
Celem algorytmu jest skonstruowanie macierzy przynależności. Jest to macierz $n \times k$, gdzie $n$ to ilość wierzchołków, a $k$ to ilość społeczności. Element $[i][j]$ oznacza jak bardzo wierzchołek i należy do społeczności j.
\\ Algorytm rozpoczyna się od pojedynczego przebiegu algorytmu dla społeczności rozłącznych. Jego wynikowa tablica jest tłumaczona tak aby numery społeczności były liczbami od $0$ do $k-1$ ($k$ -ilość społeczności w wyznaczonym podziale). Będzie podstawą do wygenerowania macierzy przynależności. Jest ona od razu aktualizowana. Do elementu $[i][j]$ dodajemy ilość połączeń wierzchołka $i$ z wierzchołkami ze społeczności $j$.\\
Następnie wywołujemy algorytm dla społeczności rozłącznych określoną ilość razy. Po każdym przebiegu wynikowa tablica jest tłumaczona, tak by społeczności odpowiadające tym w tablicy z oryginalnego przebiegu miały ten sam numer. W tym celu dla każdej społeczności znajdowana jest taka, w której ilość pokrywających się wierzchołków jest największa. Następnie macierz przynależności jest aktualizowana, analogicznie jak po początkowym przebiegu.
\\ Po wykonaniu założonych przebiegów, macierz przynależności jest normalizowana (tak by suma współczynników dla każdego wierzchołka wynosiła 1). Następnie każdemu wierzchołkowi przydzielane są społeczności, dla których współczynnik przynależności przekroczył wartość progową (obliczaną na podstawie parametru funkcji). Współczynniki dla społeczności, które nie przekroczyły wartości progowej są zerowane, a macierz znów jest normalizowana. Jeżeli wierzchołek dla wszystkich społeczności ma współczynnik 0 (tzn. jest wyizolowany), to jest on przydzielany do swojej społeczności. Jeżeli dla wierzchołka, żaden ze współczynników nie przekroczy wartości progowej, to umieszczany jest on w społeczności z największym współczynnikiem. Jest to rozwiązanie na swój sposób prowizoryczne. Takie wierzchołki mogą być bowiem czasami łącznikami pomiędzy społecznościami i w takich sytuacjach wypadałoby umieścić je we wszystkich społecznościach. Jest to jednak problem, który nie został poruszony w tej implementacji i może być obiektem usprawnień w przyszłości.
\subsubsection{Podjęte decyzje}
Metoda dla społeczności nachodzących opisana w artykule "A Fast Algorithm for Overlapping Community Detection" \cite{pw-paper3}, zakładała obecność jeszcze jednego kroku, którego celem miała być ogólna poprawa jakości wyniku. Metoda ta opierała się jednak na modularności Nicosii \cite{pw-paper2}, której obliczenie jest na tyle kosztowne, że zwiększa złożoność algorytmu do $n^3$. Z racji, że zdecydowanie pogorszyło by to czas obliczeń i negatywnie wpłynęło na możliwość wielokrotnego testowania (zwłaszcza dla grafów o kilku tysiącach wierzchołków), a także biorąc pod uwagę fakt, że wyniki bez tego kroku były zadowalające, postanowiliśmy z niego zrezygnować.\\\ Dodatkową modyfikacją jest możliwość przekazywania  opcjonalnego parametru do wywołania funkcji $louvain\_ algorithm$. Parametr ten wpływa na to jak bardzo element $\frac{\Sigma_{tot}*k_i}{2m^2}$ wpływa na zmianę modularności. Dla wartości mniejszych promuje on powstawanie niewielu rozległych społeczności, a dla większych - powstawanie wielu drobniejszych społeczności. Najlepsze wartości modularności uzyskiwane są co prawda dla wartości 1, ale parametr pozwala na dostosowywanie wyniku do naszych oczekiwań, przy nieznacznych stratach na jakości.

%-----------------------------------------------------%
%Dane testowe
%-----------------------------------------------------%
\section{Dane testowe}
Rozpoczynając pracę, zakładaliśmy, że opisane algorytmy będziemy badać na zbiorach danych udostępnianych przez firmę Facebook. Portal ten chyba najbardziej kojarzy się z ogromnym źródłem danych dotyczących społeczności. Niestety modyfikacje, które chcieliśmy zastosować, nie mogły zostać zrealizowane na datasetach ściągniętych z tego portalu. Żaden z szeroko dostępnych zbiorów nie zawierał informacji na temat liczby wspólnych znajomych, a także daty zawarcia znajomości. O ile zdobycie tej pierwszej wiadomośći jest bardzo proste przy użyciu nawet najbardziej naiwnego algorytmu brute force, tak uzyskanie dat można było przeprowadzić tylko w sposób losowy, co mogło by tylko zaburzyć osiągane wyniki. Wobec tego swe spojrzenie skierowaliśmy w stronę zbiorów, które na pierwszy rzut oka nie kojarzą się ze społecznościami tak dobrze jak Facebook.
%-----------------------------------------------------%
%NBA
%-----------------------------------------------------%
\subsection{NBA}
'I loved this game' - to slogan reklamowy towarzyszący najlepszej lidze koszykarskiej, który odnosi się także do jednego z autorów tej pracy. Wybór tego zbioru danych motywowany był prywatnymi zainteresowaniami autorów, które wiążą się także z ogólną wiedzą na temat samej ligi. Dzięki temu zyskaliśmy możliwość oceny osiąganych rezultatów 'ludzkim okiem', przez co można było je poprawiać i oceniać dzięki swego rodzaju eksperckiej wiedzy na temat NBA.

Swoją rolę odegrała tu także ogólna dostępność danych. Ich źródło stanowił portal basketball-reference.com, który stanowi internetową, koszykarską encyklopedię. Korzystając ze scrapera napisanego w języku JavaScript można było zautomatyzować proces wyszukiwania danych. Pomógł tutaj alfabetyczny spis koszykarzy - w ten sposób zdobyliśmy informację na temat każdego z nich, a także w łatwy sposób uzyskaliśmy liczbę wszystkich sezonów i klubów, w jakich w swojej karierze występował dany zawodnik. Następnie dane te zostały obrobione z wykorzystaniem SQL, w celu uzyskania relacji między zawodnikami, a także daty zawarcia znajomości. Liczba wspólnych znajomych została określona przy pomocy prostego algorytmu napisanego w języku C\#.

Graf, który uzyskaliśmy, składa się z 4800 wierzchołków. Każdy wierzchołek można przypisać zawodnikowi, który postawił swą stopę na parkietach NBA w ciągu ponad 70 lat istnienia ligi. Dwaj zawodnicy są ze sobą w relacji, jeśli kiedykolwiek zagrali ze sobą w jednym klubie. Data zawarcia znajomości to w tym wypadku data pierwszego meczu, w którym obaj zawodnicy mieli okazję ze sobą zagrać. Tworząc relacje w ten sposób uzyskaliśmy ponad 146 tysięcy krawędzi.
%-----------------------------------------------------%
%Filmweb
%-----------------------------------------------------%
\subsection{Filmweb}
Poszukując parametru daty zawarcia znajomości zwróciliśmy się także ku innej części branży rozrywkowej. Źrodło danych w tym wypadku stanowił portal filmweb.pl, który dysponuje ogromną bazą danych na temat aktorów i filmów. Skala tych danych jest tak duża, iż musieliśmy ograniczyć nasze prace tylko do polskich aktorów. W ten sposób uzyskaliśmy graf z 10 000 wierzchołków i 190031 krawędziami.

Sposób uzyskania danych był analogiczny do tego prezentowanego w przypadku grafu NBA. Skonstruowany w języku JavaScript scraper został wykorzystany do przejrzenia listy wszystkich polskich aktorów, by następnie dla każdego z nich znaleźć listę kolegów z branży, z którymi najczęśniej występował w jednym filmie. Ten zbiór uczyniliśmy znajomymi badanego aktora. Datę zawarcia znajomości w tym wypadku stanowiła data premiery pierwszego filmu/serialu, w którym dana dwójka ze sobą wystąpiła. Dodatkowo na prośbę prowadzącego zbiór danych uzupełniony został o liczbę filmów, w których dana dwójka wspólnie występowała. Informacja ta okazała się również przydatna w modyfikacji jednego z algorytmów.

Podsumowując, wierzchołki uzyskanego grafu stanowią polscy aktorzy, pobrani z ogólnodostępnej bazy filmweb. Dwaj aktorzy są ze sobą w relacji, jeśli jeden z nich znajduje się w zakładce 'najczęściej występował z ...' u drugiego. Motywację wyboru tego grafu jako testowego stanowiło ogólne zainteresowanie branżą filmową autorów pracy, a także ogólna dostępność danych. Sama etykietyzacja wierzchołków pozwoliła nam łatwiej oceniać poprawność działania algorytmów - zwłaszcza w początkowej fazie implementacji z wykorzystaniem tylko małych zbiorów danych.

%-----------------------------------------------------%
%Github
%-----------------------------------------------------%
\subsection{GitHub}

%-----------------------------------------------------%
%Wyniki
%-----------------------------------------------------%
\section{Wyniki}

%-----------------------------------------------------%
%Girvan Newman
%-----------------------------------------------------%
\subsection{Algorytm Girvan-Newmana}
\subsubsection{Analiza czasowa}
\subsubsection{Analiza jakościowa}

%-----------------------------------------------------%
%LPA
%-----------------------------------------------------%
\subsection{Label Propagation Algorithm}
\subsubsection{Analiza czasowa}
\subsubsection{Analiza jakościowa}

%-----------------------------------------------------%
%OCDLCE
%-----------------------------------------------------%
\subsection{Overlapping Community Detection by Local Community Expansion}
\subsubsection{Analiza czasowa}
\subsubsection{Analiza jakościowa}

%-----------------------------------------------------%
%Louvain
%-----------------------------------------------------%
\subsection{Algorytm Louvain}
\subsubsection{Analiza czasowa}
\subsubsection{Analiza jakościowa}

%-----------------------------------------------------%
%Porównanie
%-----------------------------------------------------%
\subsection{Porównanie}

%-----------------------------------------------------%
%Wnioski
%-----------------------------------------------------%
\subsection{Wnioski}

\newpage
\printbibliography

\end{document}


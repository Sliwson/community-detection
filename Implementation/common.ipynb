{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run read_graph.ipynb\n",
    "import collections "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_nba = None\n",
    "\n",
    "def read_all_star_sample(vertices_path,edges_path,years_back, add_names=True, add_years=True, add_friends=True):\n",
    "    global full_nba\n",
    "    \n",
    "    if full_nba == None:\n",
    "        full_nba = read_nba_full(vertices_path,edges_path,add_names, add_years, add_friends)\n",
    "        \n",
    "    if years_back == 2:\n",
    "        AllStars19_20 = [4524, 4418, 4778, 112, 3876, 1223, 2591, 3892, 614, 2889, 25, 4147, 3726, 1717, 1085, 2065, 2513, 955, 3311, 2542, 2938, 2004, 2177, 1517, 401, 2009, 3201, 266, 1620, 4393, 4396, 3719, 921, 1149, 1475, 4227, 44, 4278, 3159]\n",
    "        result = full_nba.subgraph(AllStars19_20)\n",
    "    elif years_back == 3:\n",
    "        AllStars18_20 = [4524, 4418, 4778, 112, 3876, 1223, 2591, 3892, 614, 2889, 25, 4147, 3726, 1717, 1085, 2065, 2513, 955, 3311, 2542, 2938, 2004, 2177, 1517, 401, 2009, 3201, 266, 1620, 4393, 4396, 3719, 921, 1149, 1475, 4227, 44, 4278, 3159, 1038, 1113, 1929, 3429, 4432, 1125, 863, 1588, 2586]\n",
    "        result = full_nba.subgraph(AllStars18_20)\n",
    "    elif years_back == 4:\n",
    "        AllStars17_20 = [4524, 4418, 4778, 112, 3876, 1223, 2591, 3892, 614, 2889, 25, 4147, 3726, 1717, 1085, 2065, 2513, 955, 3311, 2542, 2938, 2004, 2177, 1517, 401, 2009, 3201, 266, 1620, 4393, 4396, 3719, 921, 1149, 1475, 4227, 44, 4278, 3159, 1038, 1113, 1929, 3429, 4432, 1125, 863, 1588, 2586,4198,115,2925,1459,2235,1794]\n",
    "        result = full_nba.subgraph(AllStars17_20)\n",
    "    elif years_back == 5:\n",
    "        AllStars16_20 = [4524, 4418, 4778, 112, 3876, 1223, 2591, 3892, 614, 2889, 25, 4147, 3726, 1717, 1085, 2065, 2513, 955, 3311, 2542, 2938, 2004, 2177, 1517, 401, 2009, 3201, 266, 1620, 4393, 4396, 3719, 921, 1149, 1475, 4227, 44, 4278, 3159, 1038, 1113, 1929, 3429, 4432, 1125, 863, 1588, 2586,4198,115,2925,1459,2235,1794,415,1460,564]\n",
    "        result = full_nba.subgraph(AllStars16_20)\n",
    "    elif years_back == 6:\n",
    "        AllStars15_20 = [4524, 4418, 4778, 112, 3876, 1223, 2591, 3892, 614, 2889, 25, 4147, 3726, 1717, 1085, 2065, 2513, 955, 3311, 2542, 2938, 2004, 2177, 1517, 401, 2009, 3201, 266, 1620, 4393, 4396, 3719, 921, 1149, 1475, 4227, 44, 4278, 3159, 1038, 1113, 1929, 3429, 4432, 1125, 863, 1588, 2586,4198,115,2925,1459,2235,1794,415,1460,564,4168,2384,1142]\n",
    "        result = full_nba.subgraph(AllStars15_20)\n",
    "    elif years_back == 7:\n",
    "        AllStars14_20 = [4524, 4418, 4778, 112, 3876, 1223, 2591, 3892, 614, 2889, 25, 4147, 3726, 1717, 1085, 2065, 2513, 955, 3311, 2542, 2938, 2004, 2177, 1517, 401, 2009, 3201, 266, 1620, 4393, 4396, 3719, 921, 1149, 1475, 4227, 44, 4278, 3159, 1038, 1113, 1929, 3429, 4432, 1125, 863, 1588, 2586,4198,115,2925,1459,2235,1794,415,1460,564,4168,2384,1142,3134,1849,2145,1945,3283]\n",
    "        result = full_nba.subgraph(AllStars14_20)\n",
    "    elif years_back == 8:\n",
    "        AllStars13_20 = [4524, 4418, 4778, 112, 3876, 1223, 2591, 3892, 614, 2889, 25, 4147, 3726, 1717, 1085, 2065, 2513, 955, 3311, 2542, 2938, 2004, 2177, 1517, 401, 2009, 3201, 266, 1620, 4393, 4396, 3719, 921, 1149, 1475, 4227, 44, 4278, 3159, 1038, 1113, 1929, 3429, 4432, 1125, 863, 1588, 2586,4198,115,2925,1459,2235,1794,415,1460,564,4168,2384,1142,3134,1849,2145,1945,3283,3669,1446,718,1031,1898,2577,2492,3502]\n",
    "        result = full_nba.subgraph(AllStars13_20)\n",
    "    elif years_back == 9:\n",
    "        AllStars12_20 = [4524, 4418, 4778, 112, 3876, 1223, 2591, 3892, 614, 2889, 25, 4147, 3726, 1717, 1085, 2065, 2513, 955, 3311, 2542, 2938, 2004, 2177, 1517, 401, 2009, 3201, 266, 1620, 4393, 4396, 3719, 921, 1149, 1475, 4227, 44, 4278, 3159, 1038, 1113, 1929, 3429, 4432, 1125, 863, 1588, 2586,4198,115,2925,1459,2235,1794,415,1460,564,4168,2384,1142,3134,1849,2145,1945,3283,3669,1446,718,1031,1898,2577,2492,3502,620,3079,3672,1995,3383,4609]\n",
    "        result = full_nba.subgraph(AllStars12_20)\n",
    "    elif years_back == 10:\n",
    "        AllStars11_20 = [4524, 4418, 4778, 112, 3876, 1223, 2591, 3892, 614, 2889, 25, 4147, 3726, 1717, 1085, 2065, 2513, 955, 3311, 2542, 2938, 2004, 2177, 1517, 401, 2009, 3201, 266, 1620, 4393, 4396, 3719, 921, 1149, 1475, 4227, 44, 4278, 3159, 1038, 1113, 1929, 3429, 4432, 1125, 863, 1588, 2586,4198,115,2925,1459,2235,1794,415,1460,564,4168,2384,1142,3134,1849,2145,1945,3283,3669,1446,718,1031,1898,2577,2492,3502,620,3079,3672,1995,3383,4609,4090,65,2930,1504]\n",
    "        result = full_nba.subgraph(AllStars11_20)\n",
    "    else:\n",
    "        raise ValueError('You pass wrong number of the years to this sample. Send value from 2 to 10')\n",
    "        \n",
    "    print(\"Returned graph has \" + str(result.vcount()) + \" vertices & \" + str(result.ecount()) + \" edges\")\n",
    "    return result.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_time_scorers(vertices_path, edges_path,how_many, add_names=True, add_years=True, add_friends=True):\n",
    "    if how_many < 1 or how_many > 500:\n",
    "        raise ValueError('You passed wrong number of players to this sample. Send value from 1 to 500')\n",
    "    \n",
    "    global full_nba  \n",
    "    if full_nba == None:\n",
    "        full_nba = read_nba_full(vertices_path,edges_path,add_names, add_years, add_friends)\n",
    "\n",
    "    AllTimeScorer500 = [1,2651,2065,564,2238,3159,716,3219,2653,1788,3202,3611,4588,1142,3383,1776,115,1446,689,1230,2920,4528,1259,65,2013,208,3278,938,4396,259,1149,1120,3325,341,1611,288,1460,3369,3623,1717,1479,3576,2145,4524,715,2069,4078,2323,44,3622,994,3283,904,875,2454,2131,1526,4186,1211,3394,4181,4412,4197,2743,3311,1945,3502,31,3778,234,2803,1242,3564,336,1391,3039,1957,3030,4585,1953,2156,2674,354,4242,2310,2964,3079,2811,1315,3884,4636,2650,415,4493,1870,865,461,4601,4037,124,921,4041,1137,4737,2670,1038,2906,129,3985,1948,1465,1729,4427,4090,4350,2666,4321,335,3793,1686,3073,1931,4409,696,3425,1383,1501,2534,2126,930,2223,1715,211,2288,3347,1117,3803,4343,6,2940,2086,1188,1217,329,1640,2011,3568,4583,3869,1797,2542,1941,3715,1780,3384,4100,4244,4640,4553,2080,3020,3628,4344,2201,4620,1009,2594,1504,4525,525,409,16,1733,2585,2155,3356,2925,4609,2433,4079,906,4732,2785,1995,867,1620,957,1657,3993,1076,4260,2591,1031,3217,1739,3673,2637,2148,2577,4418,142,3031,1563,3970,2586,2048,408,1500,784,4253,3999,1475,4229,4531,4567,3182,2157,3119,691,4776,1498,2031,916,3850,4352,342,2673,955,3117,2036,2300,675,611,3167,2703,1621,3717,2659,2598,1583,817,1595,1331,2792,1459,730,1806,3536,4289,2571,3971,3133,863,4227,3643,3528,33,2949,365,2587,4623,2960,4504,2384,2009,4521,188,180,2175,2302,752,1929,3886,4091,4004,4590,3061,1594,4416,2710,3530,2584,3190,100,485,2460,1662,2151,266,127,3686,3084,1113,3458,4119,2614,2492,1898,128,3969,2144,3316,1363,3672,2429,1532,1143,4305,484,1534,3452,4727,1996,2917,1516,4642,2646,2728,1865,4007,3100,3601,3942,4432,1292,4049,2621,647,96,4641,2680,1318,1714,469,4332,1748,3931,2358,1208,4706,4489,667,2727,3547,1374,112,2523,3652,948,1224,2723,2425,3082,2821,1965,3808,1215,2130,4653,2894,1328,1994,3872,2896,3804,2159,462,3820,191,2595,2372,2138,3101,4425,731,3984,987,2881,1641,544,1555,614,2411,4624,1423,849,3365,722,2909,974,1761,4168,1794,2712,22,2513,1880,2570,718,4198,3660,4393,4212,2342,62,3579,3972,3598,2019,1257,4243,2702,744,1542,680,646,2930,301,447,4353,4138,666,2802,4608,1047,254,275,2801,2,4763,954,202,2776,1074,4206,1370,3718,4571,2183,3669,229,366,3800,1603,4324,791,1422,2109,3777,1971,4354,3749,1767,2835,997,4377,2767,3147,965,708,1125,1869,1525,2942,854,200,3200,3,215,2296,231,3939,719,155,1584,1101,248,4673,3495,2947,2965,287,2235,3731,2889,3051,630,1998,4626,3410,213,3572,1779,2257,1084,29,4773,3357,4107,2995]\n",
    "    players_table = AllTimeScorer500[0:how_many]\n",
    "    \n",
    "    result = full_nba.subgraph(players_table)\n",
    "    print(\"Returned graph has \" + str(result.vcount()) + \" vertices & \" + str(result.ecount()) + \" edges\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_nba_by_player(vertices_path, edges_path, player_name, depth, add_names=True, add_years=True, add_friends=True):\n",
    "    global full_nba\n",
    "    \n",
    "    if full_nba == None:\n",
    "        full_nba = read_nba_full(vertices_path,edges_path,add_names, add_years, add_friends)\n",
    "        \n",
    "    try:\n",
    "        index = full_nba.vs[\"name\"].index(player_name)\n",
    "    except:\n",
    "        raise ValueError('Player passed as an argument not in data set')\n",
    "        \n",
    "    result = get_bfs(full_nba,index,depth)\n",
    "    print(\"Returned graph has \" + str(result.vcount()) + \" vertices & \" + str(result.ecount()) + \" edges\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_nba_by_player(vertices_path, edges_path, player_name, depth, add_names=True, add_years=True, add_friends=True):\n",
    "    global full_nba\n",
    "    \n",
    "    if full_nba == None:\n",
    "        full_nba = read_nba_full(vertices_path,edges_path,add_names, add_years, add_friends)\n",
    "        \n",
    "    try:\n",
    "        index = full_nba.vs[\"name\"].index(player_name)\n",
    "    except:\n",
    "        raise ValueError('Player passed as an argument not in data set')\n",
    "        \n",
    "    result = get_bfs(full_nba,index,depth)\n",
    "    print(\"Returned graph has \" + str(result.vcount()) + \" vertices & \" + str(result.ecount()) + \" edges\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_filmweb = None\n",
    "\n",
    "def read_filmweb_by_actor(vertices_path, edges_path, actor_name, depth, add_names=True, add_common_movies = False, add_years=True, add_friends=True):\n",
    "    global full_filmweb\n",
    "    \n",
    "    if full_filmweb == None:\n",
    "        full_filmweb = read_filmweb_full(vertices_path, edges_path, add_names, add_common_movies, add_years, add_friends)\n",
    "    \n",
    "    search_name = \" \" + actor_name + \" \"\n",
    "    \n",
    "    try:\n",
    "        index = full_filmweb.vs[\"name\"].index(search_name)\n",
    "    except:\n",
    "        raise ValueError('Actor passed as an argument not in data set')\n",
    "    \n",
    "    result = get_bfs(full_filmweb, index, depth)\n",
    "    print(\"Returned graph has \" + str(result.vcount()) + \" vertices & \" + str(result.ecount()) + \" edges\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns bfs subgraph of g starting from vertex_id with specified depth\n",
    "def get_bfs(g, vertex_idx, depth):\n",
    "    if vertex_idx > len(g.vs):\n",
    "        raise ValueError('Requested starting index higher than length of the vertices array')\n",
    "    \n",
    "    print(\"Running bfs with \" + str(depth) + \" depth, \" + str(len(g.vs)) + \" vertices and \" + str(len(g.es)) + \" edges, begin...\")\n",
    "    all_vertices = []\n",
    "    vertices = collections.deque()\n",
    "    vertices.append(g.vs[vertex_idx])\n",
    "    \n",
    "    for v in g.vs:\n",
    "        v[\"processed\"] = False\n",
    "        v[\"distance\"] = len(g.vs)\n",
    "        \n",
    "    g.vs[vertex_idx][\"distance\"] = 0\n",
    "    \n",
    "    while (len(vertices) > 0):\n",
    "        current = vertices.popleft()\n",
    "        current[\"processed\"] = True\n",
    "        if current[\"distance\"] == depth:\n",
    "            break\n",
    "            \n",
    "        all_vertices.append(current)\n",
    "        edges = g.incident(current)\n",
    "        for edge in edges:\n",
    "            e = g.es[edge]\n",
    "            if (g.vs[e.target][\"processed\"] == False):\n",
    "                g.vs[e.target][\"distance\"] = min(g.vs[e.target][\"distance\"], current[\"distance\"] + 1)\n",
    "                vertices.append(g.vs[e.target])\n",
    "            \n",
    "    subgraph = g.subgraph(all_vertices)\n",
    "    print(\"Created bfs clone with \" + str(len(subgraph.vs)) + \" vertices and \" + str(len(subgraph.es)) + \" edges\")\n",
    "    return subgraph.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measures for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modularity(graph, community):\n",
    "    M_in = 0\n",
    "    M_out = 0\n",
    "    for node in community:\n",
    "        for edge_ind in graph.incident(node):\n",
    "            edge = graph.es[edge_ind]\n",
    "            if node == edge.target and node == edge.source:\n",
    "                continue\n",
    "            elif node == edge.target:\n",
    "                if edge.source in community:\n",
    "                    M_in+=1\n",
    "                else:\n",
    "                    M_out+=1\n",
    "            elif node  == edge.source:\n",
    "                if edge.target in community:\n",
    "                    M_in+=1\n",
    "                else:\n",
    "                    M_out+=1\n",
    "    if M_out == 0:\n",
    "        return len(graph.vs) + 1\n",
    "    return M_in / 2 / M_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modularity_f(graph, community, alpha):\n",
    "    M_in = 0\n",
    "    M_out = 0\n",
    "    for node in community:\n",
    "        edges = graph.incident(node)\n",
    "        for e in edges:\n",
    "            edge = graph.es[e]\n",
    "            if node == edge.target and node == edge.source:\n",
    "                print(\"Warn - out vertex equals current vertex\")\n",
    "            elif node == edge.target:\n",
    "                if edge.source in community:\n",
    "                    M_in+=1\n",
    "                else:\n",
    "                    M_out+=1\n",
    "            elif node == edge.source:\n",
    "                if edge.target in community:\n",
    "                    M_in+=1\n",
    "                else:\n",
    "                    M_out+=1\n",
    "    if M_in == 0 and M_out == 0:\n",
    "        return 0\n",
    "    \n",
    "    return M_in / pow(M_in + M_out, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#version supported in igraph 0.8.2 \n",
    "def modularity_new(graph, community):\n",
    "    M_in = 0\n",
    "    M_out = 0\n",
    "    for node in community:\n",
    "        for edge_ind in graph.incident(node):\n",
    "            edge = graph.es[edge_ind]\n",
    "            if node == edge.target_vertex and node == edge.source_vertex:\n",
    "                continue\n",
    "            elif node == edge.target_vertex:\n",
    "                if edge.source_vertex in community:\n",
    "                    M_in+=1\n",
    "                else:\n",
    "                    M_out+=1\n",
    "            elif node  == edge.source_vertex:\n",
    "                if edge.target_vertex in community:\n",
    "                    M_in+=1\n",
    "                else:\n",
    "                    M_out+=1\n",
    "    if M_out == 0:\n",
    "        return len(graph.vs) + 1\n",
    "    return M_in / 2 / M_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#version supported in igraph 0.8.2 \n",
    "def modularity_new_f(graph, community, alpha):\n",
    "    M_in = 0\n",
    "    M_out = 0\n",
    "    for node in community:\n",
    "        edges = graph.incident(node)\n",
    "        for e in edges:\n",
    "            edge = graph.es[e]\n",
    "            if node == edge.target_vertex and node == edge.source_vertex:\n",
    "                print(\"Warn - out vertex equals current vertex\")\n",
    "            elif node == edge.target_vertex:\n",
    "                if edge.source_vertex in community:\n",
    "                    M_in+=1\n",
    "                else:\n",
    "                    M_out+=1\n",
    "            elif node == edge.source_vertex:\n",
    "                if edge.target_vertex in community:\n",
    "                    M_in+=1\n",
    "                else:\n",
    "                    M_out+=1\n",
    "    if M_in == 0 and M_out == 0:\n",
    "        return 0\n",
    "    \n",
    "    return M_in / pow(M_in + M_out, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function returns Nicosia modularity\n",
    "#Accepts two parametres:\n",
    "#g - graph\n",
    "#belonging_table - matrix n x k, n-vertice count of g, k - community count in calculated distribution \n",
    "#belonging_table[i][j] is a degree of belonging of i vertice to j-community \n",
    "def nicosia_modularity(g,belonging_table):\n",
    "    m = get_weight_sum(g)\n",
    "    length = len(belonging_table[0])\n",
    "    table = [[0 for x in range(g.vcount())] for y in range(length)] \n",
    "    skip={}\n",
    "    for i in range(length):\n",
    "        non_zero=False\n",
    "        for j in range(g.vcount()):\n",
    "            if belonging_table[j][i]!=0:\n",
    "                non_zero=True\n",
    "        if non_zero==False:\n",
    "            skip[i]=1\n",
    "            continue\n",
    "        for j in range(g.vcount()):\n",
    "            table[i][j] = calculate_beta(g,belonging_table,j,i)\n",
    "    summ=0\n",
    "    for k in range(length):\n",
    "        if k in skip:\n",
    "            print(\"skipped \",k)\n",
    "            continue\n",
    "        for i in range(g.vcount()):\n",
    "            ki_out = get_weighted_degree_out(g,i)\n",
    "            for j in range(g.vcount()):\n",
    "                kj_in =  get_weighted_degree_in(g,j)\n",
    "\n",
    "                summ+= g[i,j]*belonging_function(belonging_table[i][k],belonging_table[j][k]) - table[k][i]*table[k][j]*ki_out*kj_in/m\n",
    "\n",
    "    summ = summ/m\n",
    "\n",
    "    return summ\n",
    "\n",
    "def calculate_beta(g,table,v,k):\n",
    "    vsum=0\n",
    "    for x in range(g.vcount()):\n",
    "        vsum += belonging_function(table[x][k],table[v][k])\n",
    "    return vsum/g.vcount()\n",
    "\n",
    "def belonging_function(coef1,coef2):\n",
    "    return 1/( (1+math.exp(-x_func(coef1)))*(1+math.exp(-x_func(coef2))) )\n",
    "\n",
    "def x_func(x):\n",
    "    return 2*x -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function accepts three parametres:\n",
    "#g - graph\n",
    "#ov - value for calculating lambda threshold\n",
    "#n - how many times an algorithm for non-overlapping has to be executed\n",
    "#algorithm - algorithm for non-overlapping that will be executed\n",
    "#Function assumes that an algorithm for non-overlapping returns an belonging matrix where a [i][j] element describes how much element i belongs to community j\n",
    "def find_overlapping_communities(g,ov,n,algorithm):\n",
    "    original_table = algorithm(g) \n",
    "    original_table = rearrange_communities(original_table)\n",
    "\n",
    "    community_count = len(set(original_table))\n",
    "    belonging_table = [[0]*community_count for i in range(g.vcount())]\n",
    "    update_community_matrix(g,belonging_table,original_table)\n",
    "\n",
    "    for x in range(n):\n",
    "        new_table = algorithm(g)\n",
    "        new_table = assign_communities(original_table,new_table)\n",
    "        update_community_matrix(g,belonging_table,new_table)\n",
    "    divide_into_communities(g,ov,belonging_table)\n",
    "\n",
    "    return belonging_table\n",
    "\n",
    "def get_overlap_percent(indices1, indices2):\n",
    "    common = list(set(indices1).intersection(indices2))\n",
    "    if len(indices1) > len(indices2):\n",
    "        return len(common) / len(indices1)\n",
    "    else:\n",
    "        return len(common) / len(indices2)\n",
    "\n",
    "def get_indices(com_table,com):\n",
    "    res_list = [i for i, value in enumerate(com_table) if com == com_table[i]] \n",
    "    return res_list\n",
    "\n",
    "def assign_communities(original_table, current_table):\n",
    "    new_table = [0] * len(current_table)\n",
    "    for x in range(len(current_table)):\n",
    "        indices = get_indices(current_table,x)\n",
    "        if len(indices)==0:\n",
    "            continue\n",
    "        best_fitting_com=-1\n",
    "        best_overlap=0\n",
    "        for y in range(len(original_table)):\n",
    "            indices2 = get_indices(original_table,y)\n",
    "            if len(indices2)==0:\n",
    "                continue\n",
    "            if get_overlap_percent(indices,indices2)>best_overlap:\n",
    "                best_overlap=get_overlap_percent(indices,indices2)\n",
    "                best_fitting_com=y\n",
    "        if(best_fitting_com != -1):\n",
    "            indices = get_indices(current_table,x)\n",
    "            for i in indices:\n",
    "                new_table[i]=best_fitting_com\n",
    "    return new_table\n",
    "\n",
    "def divide_into_communities(g,ov,belonging_table):\n",
    "    lambd=1/(ov+1)\n",
    "    normalize_belonging(belonging_table)\n",
    "    for x in range(g.vcount()):\n",
    "            g.vs[x][\"communities\"]=[]\n",
    "            for y in range(len(belonging_table[x])):\n",
    "                if belonging_table[x][y]>lambd:\n",
    "                    g.vs[x][\"communities\"].append(y+1)\n",
    "\n",
    "    for x in range(g.vcount()):\n",
    "        if len( g.vs[x][\"communities\"])==0:\n",
    "            i=belonging_table[x].index(max(belonging_table[x]))\n",
    "            g.vs[x][\"communities\"].append(i)\n",
    "            belonging_table[x][i]=1\n",
    "\n",
    "    for x in range(g.vcount()):\n",
    "        for y in range(len(belonging_table[x])):\n",
    "            if belonging_table[x][y] < lambd:\n",
    "                belonging_table[x][y]=0\n",
    "    normalize_belonging(belonging_table)\n",
    "\n",
    "def normalize_belonging(belonging_table):\n",
    "    for x in range(len(belonging_table)):\n",
    "        table_sum=sum(belonging_table[x])\n",
    "        if table_sum ==0:\n",
    "            continue\n",
    "        for y in range(len(belonging_table[x])):\n",
    "            belonging_table[x][y]=belonging_table[x][y]/table_sum\n",
    "    return belonging_table\n",
    "\n",
    "def update_community_matrix(g,belonging_table,com_table):\n",
    "    for x in range(g.vcount()):\n",
    "        if len(g.neighbors(x))==0:\n",
    "            belonging_table[x][com_table[x]]+=1\n",
    "        for y in g.neighbors(x):\n",
    "            belonging_table[x][com_table[y]]+=1\n",
    "\n",
    "def rearrange_communities(com_table):  \n",
    "    counter=0\n",
    "    new_table= com_table.copy()\n",
    "    for i in range(len(new_table)):\n",
    "        if i not in new_table:\n",
    "            for n in range(len(new_table))[i+1:]:\n",
    "                if n in new_table:\n",
    "                    indices = get_indices(new_table,n)\n",
    "                    for x in indices:\n",
    "                        new_table[x]=i\n",
    "                    counter += len(indices)\n",
    "                    break\n",
    "        if(counter == len(com_table)):\n",
    "            break\n",
    "    return new_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns graph and list of many local communities with size at least 5:\n",
    "def get_local_communities(graph):\n",
    "    communities = []\n",
    "    for v in graph.vs:\n",
    "        v[\"communities\"] = []\n",
    "    for u in graph.vs:\n",
    "        for v in graph.neighbors(u):\n",
    "            v = graph.vs[v]\n",
    "            if len(set(u[\"communities\"]).intersection(v[\"communities\"])) == 0:\n",
    "                tmp_comm = [u,v]\n",
    "                NC = list(set(graph.vs[graph.neighbors(v)]).intersection(graph.vs[graph.neighbors(u)]))\n",
    "                if len(NC) > 2:\n",
    "                    for node in NC:\n",
    "                        if modularity_new(graph, tmp_comm + [node]) > modularity_new(graph, tmp_comm):\n",
    "                            tmp_comm = tmp_comm + [node]\n",
    "                if len(tmp_comm) > 4:\n",
    "                    id = len(communities)+1\n",
    "                    communities.append({\"nodes\": tmp_comm, \"id\": id })\n",
    "                    for node in tmp_comm:\n",
    "                        node[\"communities\"].append(id)\n",
    "\n",
    "    return graph, communities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def run_single_benchmark(graph, algorithm, output_path, name):\n",
    "    print(name + ', begin...')\n",
    "    graph_desc = 'vertices: ' + str(len(graph.vs)) + ', edges: ' + str(len(graph.es))\n",
    "    begin = time.time()\n",
    "\n",
    "    algorithm(graph)\n",
    "\n",
    "    end = time.time()\n",
    "    exec_time = str(end - begin) + 's'\n",
    "    \n",
    "    file = open(output_path, \"a+\")\n",
    "    file.write(name + ': ' + graph_desc + ', time: ' + exec_time + '\\n')\n",
    "    file.close()\n",
    "    print(name + ', end...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_benchmark_sample(max_vertices):\n",
    "    print(\"Reading samples, begin...\")    \n",
    "    graphs = []\n",
    "    nbaPlayersPath = \"../Data/Basketball/Players.csv\"\n",
    "    nbaEdgesPath = \"../Data/Basketball/Edges.csv\"\n",
    "    filmwebPlayersPath = \"../Data/Filmweb/allActors.csv\"\n",
    "    filmwebEdgesPath = \"../Data/Filmweb/allActorsRelation.csv\"\n",
    "    \n",
    "    #small graphs \n",
    "    allStars18_20 = read_all_star_sample(nbaPlayersPath, nbaEdgesPath,2, True, True, True)\n",
    "    graphs.append(allStars18_20)\n",
    "    allStars11_20 = read_all_star_sample(nbaPlayersPath, nbaEdgesPath,10, True, True, True)\n",
    "    graphs.append(allStars11_20)\n",
    "    \n",
    "    all_time_scorers200 = read_all_time_scorers(nbaPlayersPath, nbaEdgesPath,200, True, True, True)\n",
    "    graphs.append(all_time_scorers200)\n",
    "    all_time_scorers300 = read_all_time_scorers(nbaPlayersPath, nbaEdgesPath,300, True, True, True)\n",
    "    graphs.append(all_time_scorers300)\n",
    "    all_time_scorers400 = read_all_time_scorers(nbaPlayersPath, nbaEdgesPath,400, True, True, True)\n",
    "    graphs.append(all_time_scorers400)\n",
    "    all_time_scorers500 = read_all_time_scorers(nbaPlayersPath, nbaEdgesPath,500, True, True, True)\n",
    "    graphs.append(all_time_scorers500)\n",
    "    \n",
    "    nba = read_nba_full(nbaPlayersPath, nbaEdgesPath, True, True, True)\n",
    "    \n",
    "    DoncicGraph = get_bfs(nba,1085,3)\n",
    "    graphs.append(DoncicGraph)\n",
    "    \n",
    "    #medium graphs\n",
    "    CurryGraph = get_bfs(nba,921,4)\n",
    "    graphs.append(CurryGraph)\n",
    "    BryantGraph = get_bfs(nba,564,6)\n",
    "    graphs.append(BryantGraph)\n",
    "    \n",
    "    KarolakGraph = read_filmweb_by_actor(filmwebPlayersPath, filmwebEdgesPath,\"Tomasz Karolak\",3, True, False, True, True)\n",
    "    graphs.append(KarolakGraph)\n",
    "    PazuraGraph = read_filmweb_by_actor(filmwebPlayersPath, filmwebEdgesPath,\"Cezary Pazura\",3, True, False, True, True)\n",
    "    graphs.append(PazuraGraph)\n",
    "    \n",
    "    #large graphs\n",
    "    graphs.append(nba)\n",
    "    \n",
    "    LindaGraph = read_filmweb_by_actor(filmwebPlayersPath, filmwebEdgesPath,\"Boguslaw Linda\",4, True, False, True, True)\n",
    "    graphs.append(LindaGraph)\n",
    "    \n",
    "    filmweb = read_filmweb_full(filmwebPlayersPath, filmwebEdgesPath, True, False, True, True)    \n",
    "    graphs.append(filmweb)\n",
    "    \n",
    "    result = [graph for graph in graphs if graph.vcount() < max_vertices]\n",
    "        \n",
    "    print(len(result))\n",
    "    print(\"Reading samples, end...\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_default_benchmark(algorithm, output_path, max_vertices):\n",
    "    samples = get_benchmark_sample(max_vertices)\n",
    "    \n",
    "    #clear file\n",
    "    file = open(output_path, \"wt\")\n",
    "    file.close()\n",
    "    \n",
    "    i = 0\n",
    "    print(\"Benchmarking, begin...\")\n",
    "    for graph in samples:\n",
    "        run_single_benchmark(graph, algorithm, output_path, 'Pass ' + str(i))\n",
    "        i += 1\n",
    "    \n",
    "    print(\"Results saved to: \" + output_path)\n",
    "    print(\"Benchmarking, end...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
